# AgentScope 学習用サンプルプロジェクト

このプロジェクトは、`AgentScope`フレームワークの主要な概念を、ステップバイステップで学ぶために作成されたサンプル集です。
https://github.com/agentscope-ai/agentscope


それぞれの`sample*.py`ファイルが、特定の機能に焦点を当てた自己完結型のプログラムになっています。

## 1. 事前準備

サンプルを実行する前に、お使いの環境で以下の準備を完了させてください。

### a. Python環境の構築

Python 3.9以上がインストールされていることを確認してください。

### b. Python仮想環境の構築とパッケージインストール (uv版)

このプロジェクトでは、高速なパッケージインストーラである`uv`の使用を推奨します。

1.  **uvのインストール**:
    お使いの環境に`uv`がインストールされていない場合は、公式の指示に従いインストールしてください。
    ```bash
    # macOS / Linux
    curl -LsSf https://astral.sh/uv/install.sh | sh
    ```

2.  **仮想環境の作成と有効化**:
    プロジェクトのルートで以下のコマンドを実行し、仮想環境を作成して有効化します。
    ```bash
    uv venv
    source .venv/bin/activate
    ```

3.  **必要なPythonパッケージのインストール**:
    `uv`を使って、`AgentScope`と関連ライブラリをインストールします。
    ```bash
    uv pip install agentscope packaging "ollama>=0.1.7"
    ```
    * `agentscope`: フレームワーク本体です。
    * `packaging`: `agentscope`が内部で利用する依存ライブラリです。
    * `ollama`: ローカルLLMであるOllamaと連携するために必要です。(`LEARNINGS.md`に基づき、バージョンを指定)

### c. Ollamaのセットアップ

`sample2`以降のサンプルでは、ローカルで動作するLLMとの連携機能を利用します。

1.  **Ollamaのインストール**: 公式サイト([https://ollama.com/](https://ollama.com/))の指示に従い、Ollamaをインストールして起動してください。

2.  **モデルのダウンロード**: サンプルでは、`gpt-oss:20b`モデルを使用します。以下のコマンドでモデルをダウンロードしてください。
    *注意: このモデルはリソースを多く消費する可能性があります。もし動作が重い場合は、`sample*.py`内のモデル名を、より軽量なモデル（例: `gemma:2b`, `llama3`）に書き換えて試してください。*

    ```bash
    ollama pull gpt-oss:20b
    ```

### d. (任意) AgentScope Studioのインストールと起動

`AgentScope`には、エージェントの対話の様子を視覚的に確認できるWebダッシュボード「AgentScope Studio」が付属しています。

1.  **AgentScope Studioのインストール**:
    `npm` (Node.jsのパッケージマネージャ) を使ってインストールします。
    ```bash
    npm install -g @agentscope/studio
    ```
    *もし`npm`がインストールされていない場合は、[Node.js公式サイト](https://nodejs.org/)からインストールしてください。*

2.  **AgentScope Studioの起動**:
    利用したい場合は、サンプル実行とは**別のターミナル**で以下のコマンドを実行してください。
    ```bash
    as_studio
    ```
    実行後、ブラウザで `http://localhost:3000` を開くとダッシュボードが表示されます。
    （`sample2_with_llm.py`の`studio_url`のコメントアウトを解除すると連携できます。）

---

## 2. サンプル一覧

### `sample1_basic_dialogue.py`

*   **学ぶこと**: `AgentScope`の最も基本的な構造。LLMを使わずに、2体のエージェントが事前に定義されたメッセージを交換します。`AgentBase`の継承、`Msg`オブジェクト、非同期でのエージェント呼び出し（`await`）の基本を学びます。
*   **実行方法**: `python sample1_basic_dialogue.py`
*   **期待される動作**: 2体のエージェント（アリスとボブ）が挨拶を交わす様子がコンソールに表示されます。

### `sample2_with_llm.py`

*   **学ぶこと**: エージェントをローカルLLM（Ollama）に接続する方法。`OllamaChatModel`と`ReActAgent`を使って、ユーザーの入力に対してLLMが生成した応答を返します。
*   **実行方法**: `python sample2_with_llm.py`
*   **期待される動作**: プログラムが起動し、コンソールに質問を入力するよう促されます。入力した質問に対して、Ollamaで動作するLLMが考えた応答が返ってきます。`exit`と入力すると終了します。

### `sample3_with_tool.py`

*   **学ぶこと**: エージェントに「ツール」を使わせる方法。簡単なPython関数をツールとして定義し、`Toolkit`に登録してエージェントに渡します。LLMがユーザーの意図を解釈し、自律的にツールを呼び出す様子を確認できます。
*   **実行方法**: `python sample3_with_tool.py`
*   **期待される動作**: 起動後、「今の時間は？」や「現在時刻を教えて」と入力します。すると、エージェントが`get_current_time`関数を呼び出し、その実行結果を含んだ応答を返します。

### `sample4_multi_agent.py`

*   **学ぶこと**: 複数のエージェントが協調してタスクを解決する方法。役割の異なる2体のエージェント（計画を作成する`プランナー`と、それを批評する`クリティック`）を連携させ、より質の高い応答を生成するプロセスを実装します。
*   **実行方法**: `python sample4_multi_agent.py`
*   **期待される動作**: 「Pythonを学ぶための計画を立てて」のようなタスクを入力すると、まずプランナーが計画案を作成し、次にクリティックがその計画案に対する改善案を提示します。両方の結果がコンソールに表示されます。

---

## 3. 学べる主要なAgentScopeの概念

このサンプル集を通して、以下の`AgentScope`のコアな概念に触れることができます。

*   **Agent**: 対話の主体。`AgentBase`を継承してカスタムしたり、`UserAgent`や`ReActAgent`のような組み込みエージェントを利用したりします。
*   **Message (`Msg`)**: エージェント間で交換される情報の単位。`content`（内容）、`name`（送信者名）、`role`（役割）といった属性を持ちます。
*   **Model**: エージェントの「脳」となるLLM。`OllamaChatModel`などを使って、様々なモデルに接続できます。
*   **Tool / Toolkit**: エージェントが利用できる外部機能。Python関数を`Toolkit`に登録することで、LLMが自律的に呼び出せるようになります。
*   **非同期処理**: エージェントの呼び出しは `await agent(...)` のように、Pythonの`asyncio`に基づいた非同期処理が基本となります。
*   **Orchestration (連携フロー)**: `async def`関数内でエージェントの呼び出し順序を制御することで、単純な応答だけでなく、複数のエージェントが協調する複雑なタスクフローを構築できます。

---

## 4. 次のステップ

このサンプルプロジェクトで基本を学んだら、ぜひ以下のステップに挑戦して、`AgentScope`の理解をさらに深めてみてください。

*   **プロンプトのカスタマイズ**:
    - `sample2_with_llm.py` や `sample4_multi_agent.py` の `sys_prompt` を変更して、エージェントの性格や役割を自由に変えてみましょう。（例：「関西弁を話すアシスタント」「厳しい批評家」など）

*   **新しいツールの追加**:
    - `sample3_with_tool.py` を参考に、あなた自身のPython関数をツールとしてエージェントに提供してみましょう。Web APIを叩く、ファイル操作をするなど、可能性は無限大です。

*   **エージェントの組み合わせ変更**:
    - `sample4_multi_agent.py` の構成を変えて、3体以上のエージェントが連携する、より複雑なワークフローを構築してみましょう。

*   **他のモデルを試す**:
    - `Ollama`で `llama3` や `mistral` といった他のLLMをダウンロードし、`model_name` を書き換えて応答の違いを比較してみましょう。
